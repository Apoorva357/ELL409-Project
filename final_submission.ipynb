{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "data_path = 'train.csv'\n",
    "file_data = pd.read_csv(data_path)\n",
    "print(file_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = file_data['type_of_attack']\n",
    "print(train_data)\n",
    "counter1 = Counter(train_data)\n",
    "values1 = list(counter1.keys())\n",
    "frequencies1 = list(counter1.values())\n",
    "plt.bar(values1, frequencies1)\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Occurrences of Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "features_na = [feature for feature in file_data.columns if file_data[feature].isnull().sum()>1]\n",
    "print(features_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(file_data.shape)\n",
    "file_data = file_data.drop('Id', axis = 1)\n",
    "print(file_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMERICAL FEATURES\n",
    "features_num = [feature for feature in file_data.columns if file_data[feature].dtype != 'O']\n",
    "print(features_num)\n",
    "print(len(features_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL FEATURES\n",
    "features_cat = [feature for feature in file_data.columns if file_data[feature].dtype == 'O']\n",
    "print(features_cat)\n",
    "print(len(features_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISCRETE FEATURES\n",
    "features_dis = [feature for feature in features_num if len(file_data[feature].unique()) < 25]\n",
    "print(features_dis)\n",
    "print(len(features_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUOUS FEATURES\n",
    "features_cont = [feature for feature in features_num if len(file_data[feature].unique()) >= 25]\n",
    "print(features_cont)\n",
    "print(len(features_cont))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_dis:\n",
    "    print(feature, len(file_data[feature].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for feature in features_cat:\n",
    "    data = file_data.copy()\n",
    "    for category in data[feature].unique():\n",
    "        attack_counts = data[data[feature] == category]['type_of_attack'].value_counts()\n",
    "        plt.figure(figsize=(6,6))\n",
    "        attack_counts.plot.pie(autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
    "        plt.ylabel('')\n",
    "        plt.title(f'Distribution of type_of_attack for {category} in {feature}')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_cont:\n",
    "    data = file_data.copy()\n",
    "    data[feature].hist(bins = 25)\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features_cont:\n",
    "    plt.scatter(file_data[feature], file_data['type_of_attack'])\n",
    "    plt.ylabel('type_of_attack')\n",
    "    plt.xlabel(feature)\n",
    "    plt.title(feature)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODING\n",
    "\n",
    "data_onehot = file_data.copy()\n",
    "for feature in features_cat:\n",
    "    if (feature == 'type_of_attack'):\n",
    "        continue\n",
    "    data_onehot = pd.get_dummies(data_onehot, columns=[feature], prefix=feature, drop_first=True)\n",
    "    \n",
    "print(data_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING FEATURES WITH VARIANCE LESS THAN THE THRESHOLD\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "var_thres = VarianceThreshold(threshold=1e-5)\n",
    "y = data_onehot['type_of_attack'].to_numpy()\n",
    "X = data_onehot.drop('type_of_attack', axis = 1)\n",
    "var_thres.fit(X)\n",
    "const_columns = [column for column in X.columns if column not in X.columns[var_thres.get_support()]]\n",
    "print(const_columns)\n",
    "print(X.shape)\n",
    "X = X.drop(const_columns, axis = 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING FEATURES HAVING MUTUAL_INFO <= 1e-5\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_info = mutual_info_classif(X, y)\n",
    "mutual_info = pd.Series(mutual_info)\n",
    "mutual_info.index = X.columns\n",
    "mutual_info.sort_values(ascending=False)\n",
    "mutual_info.sort_values(ascending=False).plot.bar(figsize = (20, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mi_features = mutual_info[mutual_info <= 1e-5].index\n",
    "print(X.shape)\n",
    "X = X.drop(columns = zero_mi_features)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELIVERABLES: mutual_info, const_columns, features_cat (for ONE-HOT ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE MODEL, LOGISTIC REGRESSION\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression(random_state=42, max_iter=100)\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred1 = model1.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred1)}\")\n",
    "print(classification_report(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model2 = SVC(random_state=42, max_iter=1000)\n",
    "model2.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred2 = model2.predict(X_test_scaled)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred2)}\")\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    \n",
    "    # Plotting the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    disp.plot(cmap='viridis', ax=ax, xticks_rotation='vertical')\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "class_names = ['ipsweep probe', 'back dos', 'satan probe', 'portsweep probe', 'normal']\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)  # You can tune n_neighbors\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred3 = knn_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred3)\n",
    "print(f\"KNN Test Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred3, target_names=class_names))\n",
    "plot_confusion_matrix(y_test, y_pred3, class_names)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "n_classes = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train, num_classes=n_classes)\n",
    "y_test = to_categorical(y_test, num_classes=n_classes)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_dim=input_dim),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(n_classes, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "yp = model.predict(X_test)\n",
    "yp_classes = np.argmax(yp, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_classes, yp_classes):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_classes, yp_classes))\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
